{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bdv_toolz.cli import nd2_to_bdv\n",
    "import sys\n",
    "\n",
    "from bdv_toolz.bdv_creation import create_bdv_n5_multi_tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define paths using raw strings to avoid escape sequence issues\n",
    "nd2_file_path = Path(r\"\\\\fs.ista.ac.at\\group\\siegegrp\\ThNe\\_Bioimaging\\development_retina\\slide_P15_M_1001.nd2\")\n",
    "output_file_path = Path(r\"\\\\fs.ista.ac.at\\group\\siegegrp\\ThNe\\development_retina\\test_slide_P15_M_1001.n5\")\n",
    "\n",
    "# Ensure paths exist (optional)\n",
    "if not nd2_file_path.exists():\n",
    "    print(f\"Warning: ND2 file not found at {nd2_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image info\n",
      "================================================================\n",
      "N_TILES: 50\n",
      "N_RNDS: 1\n",
      "N_CH: 4\n",
      "ARRAY SHAPE (TCZYZ): (1, 4, 136, 2048, 2048)\n",
      "\n",
      "Your selection\n",
      "================================================================\n",
      "Tiles: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Channels: [0, 1, 2, 3]\n",
      "Z slices: slice(None, None, None)\n",
      "\n",
      "Output BDV XML/N5: \\\\fs.ista.ac.at\\group\\siegegrp\\ThNe\\development_retina\\test_slide_P15_M_1001.n5\n",
      "Multi-resolution pyramid down-scale factors: ((1, 2, 2), (1, 2, 2))\n",
      "Chromatic abberation correcton:\n",
      "Flat-field correction bright-field images:\n",
      "Overwrite skip\n",
      "Chunks: (64, 256, 256)\n",
      "Pyramid Chunks: [(32, 128, 128), (32, 128, 128)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating N5 for Tile: 0, Round: 0, Channel: 0,:   0%|          | 1/200 [00:03<12:22,  3.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_bdv_n5_multi_tile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnd2_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_n5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_slc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43myes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mca_json\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mff_json\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownscale_factors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_tile_positions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\bdv_toolz\\bdv_creation.py:165\u001b[0m, in \u001b[0;36mcreate_bdv_n5_multi_tile\u001b[1;34m(fn, out_n5, tiles, rounds, channels, z_slc, chunks, overwrite, yes, ca_json, ff_json, downscale_factors, read_tile_positions)\u001b[0m\n\u001b[0;32m    162\u001b[0m                         matrix_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(ca_matrices[ci])\n\u001b[0;32m    163\u001b[0m                         data \u001b[38;5;241m=\u001b[39m affine_transform(data, matrix_inv)\n\u001b[1;32m--> 165\u001b[0m                     \u001b[43mmake_bdv_from_dask_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_n5\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdownscale_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownscale_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdownscale_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                        \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msetup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel_multi_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtimepoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msetup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                        \u001b[49m\u001b[43maffine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mforce_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mti\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43millumination\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mangle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdownsample_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownsample_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\pybdv\\converter.py:771\u001b[0m, in \u001b[0;36mmake_bdv_from_dask_array\u001b[1;34m(data, output_path, downscale_factors, downscale_mode, resolution, unit, setup_id, timepoint, setup_name, affine, attributes, overwrite, chunks, downsample_chunks, n_threads, force_dtype, compute, return_stored)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downscale_factors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# set single level downscale factor\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     factors \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m--> 771\u001b[0m factors, array \u001b[38;5;241m=\u001b[39m \u001b[43mmake_scales_dask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_n5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownscale_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownscale_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsample_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownsample_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtimepoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimepoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mreturn_stored\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_stored\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# write the format specific metadata in the output container\u001b[39;00m\n\u001b[0;32m    778\u001b[0m write_n5_metadata(data_path, factors, resolution, setup_id, timepoint,\n\u001b[0;32m    779\u001b[0m                   overwrite\u001b[38;5;241m=\u001b[39moverwrite_data)\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\pybdv\\converter.py:627\u001b[0m, in \u001b[0;36mmake_scales_dask\u001b[1;34m(data, data_path, is_n5, downscale_factors, downscale_func, ndim, setup_id, downsample_chunks, timepoint, overwrite, force_dtype, compute, return_stored)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (k, v), save_chunks \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pyramid\u001b[38;5;241m.\u001b[39mitems(), save_chunks_all):\n\u001b[0;32m    624\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(group\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    625\u001b[0m             name\u001b[38;5;241m=\u001b[39mk, shape\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdtype, chunks\u001b[38;5;241m=\u001b[39msave_chunks, compressor\u001b[38;5;241m=\u001b[39mGZip(), overwrite\u001b[38;5;241m=\u001b[39moverwrite\n\u001b[0;32m    626\u001b[0m         ))\n\u001b[1;32m--> 627\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyramid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_stored\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_stored\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# add first level to factors\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downscale_factors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\dask\\array\\core.py:1262\u001b[0m, in \u001b[0;36mstore\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute:\n\u001b[0;32m   1261\u001b[0m     store_dsk \u001b[38;5;241m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[1;32m-> 1262\u001b[0m     compute_as_if_collection(Array, store_dsk, map_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\dask\\base.py:395\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[1;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mscheduler, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, get\u001b[38;5;241m=\u001b[39mget)\n\u001b[0;32m    394\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m schedule(dsk2, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\dask\\threaded.py:91\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     89\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 91\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     92\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     93\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     94\u001b[0m     dsk,\n\u001b[0;32m     95\u001b[0m     keys,\n\u001b[0;32m     96\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     97\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     98\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    100\u001b[0m )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\dask\\local.py:505\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    504\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m    507\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\dask\\local.py:133\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Empty:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_bdv_n5_multi_tile(\n",
    "        nd2_file_path, \n",
    "        out_n5= output_file_path,\n",
    "        tiles = None,\n",
    "        channels = None,\n",
    "        rounds = None,\n",
    "        z_slc = None,\n",
    "        yes = True,\n",
    "        ca_json = None,\n",
    "        ff_json = None,\n",
    "        overwrite = 'skip',\n",
    "        downscale_factors = ((1,2,2),(1,2,2)),\n",
    "        read_tile_positions = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BioImage in module bioio.bio_image:\n",
      "\n",
      "class BioImage(bioio_base.image_container.ImageContainer)\n",
      " |  BioImage(image: Union[str, pathlib.Path, numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray, List[Union[numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray]], List[Union[str, pathlib.Path]]], reader: Optional[Type[bioio_base.reader.Reader]] = None, reconstruct_mosaic: bool = True, use_plugin_cache: bool = False, fs_kwargs: Dict[str, Any] = {}, **kwargs: Any)\n",
      " |  \n",
      " |  BioImage takes microscopy image data types (files or arrays) of varying\n",
      " |  dimensions (\"ZYX\", \"TCZYX\", \"CYX\") and reads them as consistent 5D \"TCZYX\"\n",
      " |  (\"Time-Channel-Z-Y-X\") ordered array(s). The data and metadata are lazy\n",
      " |  loaded and can be accessed as needed.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  image: biob.types.ImageLike\n",
      " |      A string, Path, fsspec supported URI, or arraylike to read.\n",
      " |  reader: Optional[Type[Reader]]\n",
      " |      The Reader class to specifically use for reading the provided image.\n",
      " |      Default: None (find matching reader)\n",
      " |  reconstruct_mosaic: bool\n",
      " |      Boolean for setting that data for this object to the reconstructed / stitched\n",
      " |      mosaic image.\n",
      " |      Default: True (reconstruct the mosaic image from tiles)\n",
      " |      Notes: If True and image is a mosaic, data will be fully reconstructed and\n",
      " |      stitched array.\n",
      " |      If True and base reader doesn't support tile stitching, data won't be stitched\n",
      " |      and instead will have an `M` dimension for tiles.\n",
      " |      If False and image is a mosaic, data won't be stitched and instead will have an\n",
      " |      `M` dimension for tiles.\n",
      " |      If image is not a mosaic, data won't be stitched or have an `M` dimension for\n",
      " |      tiles.\n",
      " |  use_plugin_cache: bool default False\n",
      " |      Boolean for setting whether to use a plugin of the installed caches rather than\n",
      " |      checking for installed plugins on each `BioImage` instance init.\n",
      " |      If True, will use the cache of installed plugins discovered last `BioImage`\n",
      " |      init.\n",
      " |  fs_kwargs: Dict[str, Any]\n",
      " |      Any specific keyword arguments to pass down to the fsspec created filesystem.\n",
      " |      Default: {}\n",
      " |  kwargs: Any\n",
      " |      Extra keyword arguments that will be passed down to the reader subclass.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Initialize an image then read the file and return specified slices as a numpy\n",
      " |  array.\n",
      " |  \n",
      " |  >>> img = BioImage(\"my_file.tiff\")\n",
      " |  ... zstack_t8 = img.get_image_data(\"ZYX\", T=8, C=0)\n",
      " |  \n",
      " |  Initialize an image, construct a delayed dask array for certain slices, then\n",
      " |  read only the specified chunk of data.\n",
      " |  \n",
      " |  >>> img = BioImage(\"my_file.czi\")\n",
      " |  ... zstack_t8 = img.get_image_dask_data(\"ZYX\", T=8, C=0)\n",
      " |  ... zstack_t8_data = zstack_t8.compute()\n",
      " |  \n",
      " |  Initialize an image with a dask or numpy array.\n",
      " |  \n",
      " |  >>> data = np.random.rand(100, 100)\n",
      " |  ... img = BioImage(data)\n",
      " |  \n",
      " |  Initialize an image from S3 with s3fs.\n",
      " |  \n",
      " |  >>> img = BioImage(\"s3://my_bucket/my_file.tiff\")\n",
      " |  \n",
      " |  Initialize an image and pass arguments to the reader using kwargs.\n",
      " |  \n",
      " |  >>> img = BioImage(\"my_file.czi\", chunk_dims=[\"T\", \"Y\", \"X\"])\n",
      " |  \n",
      " |  Initialize an image, change scene, read data to numpy.\n",
      " |  \n",
      " |  >>> img = BioImage(\"my_many_scene.czi\")\n",
      " |  ... img.set_scene(\"Image:3\")\n",
      " |  ... img.data\n",
      " |  \n",
      " |  Initialize an image with a specific reader. This is useful if you know the file\n",
      " |  type in advance or would like to skip a few of the file format checks we do\n",
      " |  internally. Useful when reading from remote sources to reduce network round trips.\n",
      " |  \n",
      " |  >>> img = BioImage(\"malformed_metadata.ome.tiff\", reader=readers.TiffReader)\n",
      " |  \n",
      " |  Data for a mosaic file is returned pre-stitched (if the base reader supports it).\n",
      " |  \n",
      " |  >>> img = BioImage(\"big_mosaic.czi\")\n",
      " |  ... img.dims  # <Dimensions [T: 40, C: 3, Z: 1, Y: 30000, X: 45000]>\n",
      " |  \n",
      " |  Data for mosaic file can be explicitly returned as tiles.\n",
      " |  This is the same data as a reconstructed mosaic except that the tiles are\n",
      " |  stored in their own dimension (M).\n",
      " |  \n",
      " |  >>> img = BioImage(\"big_mosaic.czi\", reconstruct_mosaic=False)\n",
      " |  ... img.dims  # <Dimensions [M: 150, T: 40, C: 3, Z: 1, Y: 200, X: 300]>\n",
      " |  \n",
      " |  Data is mosaic file but reader doesn't support tile stitching.\n",
      " |  \n",
      " |  >>> img = BioImage(\"unsupported_mosaic.ext\")\n",
      " |  ... img.dims  # <Dimensions [M: 100, T: 1, C: 2, Z: 1, Y: 400, X: 400]>\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  If your image is made up of mosaic tiles, data and dimension information returned\n",
      " |  from this object will be from the tiles already stitched together.\n",
      " |  \n",
      " |  If you do not want the image pre-stitched together, you can use the base reader\n",
      " |  by either instantiating the reader independently or using the `.reader` property.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BioImage\n",
      " |      bioio_base.image_container.ImageContainer\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, image: Union[str, pathlib.Path, numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray, List[Union[numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray]], List[Union[str, pathlib.Path]]], reader: Optional[Type[bioio_base.reader.Reader]] = None, reconstruct_mosaic: bool = True, use_plugin_cache: bool = False, fs_kwargs: Dict[str, Any] = {}, **kwargs: Any)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  get_dask_stack(self, **kwargs: Any) -> dask.array.core.Array\n",
      " |      Get all scenes stacked in to a single array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stack: da.Array\n",
      " |          The fully stacked array. This can be 6+ dimensions with Scene being\n",
      " |          the first dimension.\n",
      " |      kwargs: Any\n",
      " |          Extra keyword arguments that will be passed down to the\n",
      " |          generate stack function.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      bioio_base.transforms.generate_stack:\n",
      " |          Underlying function for generating various scene stacks.\n",
      " |  \n",
      " |  get_image_dask_data(self, dimension_order_out: Optional[str] = None, **kwargs: Any) -> dask.array.core.Array\n",
      " |      Get specific dimension image data out of an image as a dask array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dimension_order_out: Optional[str]\n",
      " |          A string containing the dimension ordering desired for the returned ndarray.\n",
      " |          Default: dimensions.DEFAULT_DIMENSION_ORDER (with or without Samples)\n",
      " |      \n",
      " |      kwargs: Any\n",
      " |          * C=1: specifies Channel 1\n",
      " |          * T=3: specifies the fourth index in T\n",
      " |          * D=n: D is Dimension letter and n is the index desired. D should not be\n",
      " |            present in the dimension_order_out.\n",
      " |          * D=[a, b, c]: D is Dimension letter and a, b, c is the list of indices\n",
      " |            desired. D should be present in the dimension_order_out.\n",
      " |          * D=(a, b, c): D is Dimension letter and a, b, c is the tuple of indices\n",
      " |            desired. D should be present in the dimension_order_out.\n",
      " |          * D=range(...): D is Dimension letter and range is the standard Python\n",
      " |            range function. D should be present in the dimension_order_out.\n",
      " |          * D=slice(...): D is Dimension letter and slice is the standard Python\n",
      " |            slice function. D should be present in the dimension_order_out.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data: da.Array\n",
      " |          The image data with the specified dimension ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Specific index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... c1 = img.get_image_dask_data(\"ZYX\", C=1)\n",
      " |      \n",
      " |      List of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_and_second = img.get_image_dask_data(\"CZYX\", C=[0, 1])\n",
      " |      \n",
      " |      Tuple of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_and_last = img.get_image_dask_data(\"CZYX\", C=(0, -1))\n",
      " |      \n",
      " |      Range of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_three = img.get_image_dask_data(\"CZYX\", C=range(3))\n",
      " |      \n",
      " |      Slice selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... every_other = img.get_image_dask_data(\"CZYX\", C=slice(0, -1, 2))\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a requested dimension is not present in the data the dimension is\n",
      " |      added with a depth of 1.\n",
      " |      \n",
      " |      See `bioio_base.transforms.reshape_data` for more details.\n",
      " |  \n",
      " |  get_image_data(self, dimension_order_out: Optional[str] = None, **kwargs: Any) -> numpy.ndarray\n",
      " |      Read the image as a numpy array then return specific dimension image data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dimension_order_out: Optional[str]\n",
      " |          A string containing the dimension ordering desired for the returned ndarray.\n",
      " |          Default: dimensions.DEFAULT_DIMENSION_ORDER (with or without Samples)\n",
      " |      \n",
      " |      kwargs: Any\n",
      " |          * C=1: specifies Channel 1\n",
      " |          * T=3: specifies the fourth index in T\n",
      " |          * D=n: D is Dimension letter and n is the index desired. D should not be\n",
      " |            present in the dimension_order_out.\n",
      " |          * D=[a, b, c]: D is Dimension letter and a, b, c is the list of indices\n",
      " |            desired. D should be present in the dimension_order_out.\n",
      " |          * D=(a, b, c): D is Dimension letter and a, b, c is the tuple of indices\n",
      " |            desired. D should be present in the dimension_order_out.\n",
      " |          * D=range(...): D is Dimension letter and range is the standard Python\n",
      " |            range function. D should be present in the dimension_order_out.\n",
      " |          * D=slice(...): D is Dimension letter and slice is the standard Python\n",
      " |            slice function. D should be present in the dimension_order_out.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data: np.ndarray\n",
      " |          The image data with the specified dimension ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Specific index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... c1 = img.get_image_data(\"ZYX\", C=1)\n",
      " |      \n",
      " |      List of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_and_second = img.get_image_data(\"CZYX\", C=[0, 1])\n",
      " |      \n",
      " |      Tuple of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_and_last = img.get_image_data(\"CZYX\", C=(0, -1))\n",
      " |      \n",
      " |      Range of index selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... first_three = img.get_image_dask_data(\"CZYX\", C=range(3))\n",
      " |      \n",
      " |      Slice selection\n",
      " |      \n",
      " |      >>> img = BioImage(\"s_1_t_1_c_10_z_20.ome.tiff\")\n",
      " |      ... every_other = img.get_image_data(\"CZYX\", C=slice(0, -1, 2))\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * If a requested dimension is not present in the data the dimension is\n",
      " |        added with a depth of 1.\n",
      " |      * This will preload the entire image before returning the requested data.\n",
      " |      \n",
      " |      See `bioio_base.transforms.reshape_data` for more details.\n",
      " |  \n",
      " |  get_mosaic_tile_position(self, mosaic_tile_index: int, **kwargs: int) -> Tuple[int, int]\n",
      " |      Get the absolute position of the top left point for a single mosaic tile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mosaic_tile_index: int\n",
      " |          The index for the mosaic tile to retrieve position information for.\n",
      " |      kwargs: int\n",
      " |          The keywords below allow you to specify the dimensions that you wish\n",
      " |          to match. If you under-specify the constraints you can easily\n",
      " |          end up with a massive image stack.\n",
      " |                     Z = 1   # The Z-dimension.\n",
      " |                     C = 2   # The C-dimension (\"channel\").\n",
      " |                     T = 3   # The T-dimension (\"time\").\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top: int\n",
      " |          The Y coordinate for the tile position.\n",
      " |      left: int\n",
      " |          The X coordinate for the tile position.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      UnexpectedShapeError\n",
      " |          The image has no mosaic dimension available.\n",
      " |  \n",
      " |  get_mosaic_tile_positions(self, **kwargs: int) -> List[Tuple[int, int]]\n",
      " |      Get the absolute positions of the top left points for each mosaic tile\n",
      " |      matching the specified dimensions and current scene.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs: int\n",
      " |          The keywords below allow you to specify the dimensions that you wish\n",
      " |          to match. If you under-specify the constraints you can easily\n",
      " |          end up with a massive image stack.\n",
      " |                     Z = 1   # The Z-dimension.\n",
      " |                     C = 2   # The C-dimension (\"channel\").\n",
      " |                     T = 3   # The T-dimension (\"time\").\n",
      " |                     M = 4   # The mosaic tile index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mosaic_tile_positions: List[Tuple[int, int]]\n",
      " |          List of the Y and X coordinate for the tile positions.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      UnexpectedShapeError\n",
      " |          The image has no mosaic dimension available.\n",
      " |      NotImplementedError\n",
      " |          Unable to combine M dimension with other dimensions when finding\n",
      " |          tiles matching kwargs\n",
      " |  \n",
      " |  get_stack(self, **kwargs: Any) -> numpy.ndarray\n",
      " |      Get all scenes stacked in to a single array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stack: np.ndarray\n",
      " |          The fully stacked array. This can be 6+ dimensions with Scene being\n",
      " |          the first dimension.\n",
      " |      kwargs: Any\n",
      " |          Extra keyword arguments that will be passed down to the\n",
      " |          generate stack function.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      bioio_base.transforms.generate_stack:\n",
      " |          Underlying function for generating various scene stacks.\n",
      " |  \n",
      " |  get_xarray_dask_stack(self, **kwargs: Any) -> xarray.core.dataarray.DataArray\n",
      " |      Get all scenes stacked in to a single array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stack: xr.DataArray\n",
      " |          The fully stacked array. This can be 6+ dimensions with Scene being\n",
      " |          the first dimension.\n",
      " |      kwargs: Any\n",
      " |          Extra keyword arguments that will be passed down to the\n",
      " |          generate stack function.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      bioio_base.transforms.generate_stack:\n",
      " |          Underlying function for generating various scene stacks.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When requesting an xarray stack, the first scene's coordinate planes\n",
      " |      are used for the returned xarray DataArray object coordinate planes.\n",
      " |  \n",
      " |  get_xarray_stack(self, **kwargs: Any) -> xarray.core.dataarray.DataArray\n",
      " |      Get all scenes stacked in to a single array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stack: xr.DataArray\n",
      " |          The fully stacked array. This can be 6+ dimensions with Scene being\n",
      " |          the first dimension.\n",
      " |      kwargs: Any\n",
      " |          Extra keyword arguments that will be passed down to the\n",
      " |          generate stack function.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      bioio_base.transforms.generate_stack:\n",
      " |          Underlying function for generating various scene stacks.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When requesting an xarray stack, the first scene's coordinate planes\n",
      " |      are used for the returned xarray DataArray object coordinate planes.\n",
      " |  \n",
      " |  save(self, uri: Union[str, pathlib.Path], select_scenes: Union[List[str], Tuple[str, ...], NoneType] = None) -> None\n",
      " |      Saves the file data to OME-TIFF format with general naive best practices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      uri: biob.types.PathLike\n",
      " |          The URI or local path for where to save the data.\n",
      " |          Note: Can only write to local file systems.\n",
      " |      select_scenes: Optional[Union[List[str], Tuple[str, ...]]]\n",
      " |          Which scenes in the image to save to the file.\n",
      " |          Default: None (save all scenes)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See `bioio.writers.OmeTiffWriter` for more in-depth specification\n",
      " |      and the `bioio.writers` module as a whole for list of all available\n",
      " |      file writers.\n",
      " |      \n",
      " |      When reading in the produced OME-TIFF file, scenes IDs may have changed.\n",
      " |      This is due to how certain file and metadata formats do or do-not have IDs\n",
      " |      and simply names. In converting to OME-TIFF we will always store the scene\n",
      " |      ids in each Image's name attribute but IDs will be generated. The order of the\n",
      " |      scenes will be the same (or whatever order was specified / provided).\n",
      " |  \n",
      " |  set_resolution_level(self, resolution_level: int) -> None\n",
      " |      Set the operating resolution level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      resolution_level: int\n",
      " |          The selected resolution level to set as current.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          The provided level is not found in the available list of resolution levels.\n",
      " |  \n",
      " |  set_scene(self, scene_id: Union[str, int]) -> None\n",
      " |      Set the operating scene.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scene_id: Union[str, int]\n",
      " |          The scene id (if string) or scene index (if integer)\n",
      " |          to set as the operating scene.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          The provided scene id or index is not found in the available scene id list.\n",
      " |      TypeError\n",
      " |          The provided value wasn't a string (scene id) or integer (scene index).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  determine_plugin(image: Union[str, pathlib.Path, numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray, List[Union[numpy.ndarray, dask.array.core.Array, xarray.core.dataarray.DataArray]], List[Union[str, pathlib.Path]]], fs_kwargs: Dict[str, Any] = {}, use_plugin_cache: bool = False, **kwargs: Any) -> bioio.plugins.PluginEntry\n",
      " |      Determine the appropriate plugin to read a given image.\n",
      " |      \n",
      " |      This function identifies the most suitable plugin to read the provided image\n",
      " |      based on its type or file extension. It leverages the installed plugins for\n",
      " |      `bioio`, each of which supports a subset of image formats. If a suitable\n",
      " |      plugin is found, it is returned; otherwise, an error is raised.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      image : biob.types.ImageLike\n",
      " |          The image to be read. This can be a file path (str or Path) or\n",
      " |          an array-like object (e.g., numpy array).\n",
      " |      fs_kwargs : Dict[str, Any], optional\n",
      " |          Additional keyword arguments to be passed to the file system handler.\n",
      " |      use_plugin_cache : bool, optional\n",
      " |          Whether to use a cached version of the plugin mapping, by default False.\n",
      " |      **kwargs : Any\n",
      " |          Additional keyword arguments for plugin-specific configurations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      PluginEntry\n",
      " |          A `PluginEntry` NamedTuple which is a wrapper of release information and\n",
      " |          reader references for an individual plugin.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      exceptions.UnsupportedFileFormatError\n",
      " |          Raised if no suitable reader plugin can be found for the provided image.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function performs the following steps:\n",
      " |      1. Fetches an updated mapping of available plugins,\n",
      " |         optionally using a cached version.\n",
      " |      2. If the `image` is a file path (str or Path), it checks for a matching\n",
      " |         plugin based on the file extension.\n",
      " |      3. If the `image` is an array-like object, it attempts to use the\n",
      " |         built-in `ArrayLikeReader`.\n",
      " |      4. If no suitable plugin is found, raises an `UnsupportedFileFormatError`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      To determine the appropriate plugin for a given image file:\n",
      " |      \n",
      " |      >>> image_path = \"example_image.tif\"\n",
      " |      >>> plugin = determine_plugin(image_path)\n",
      " |      >>> print(plugin)\n",
      " |      \n",
      " |      To determine the appropriate plugin for an array-like image:\n",
      " |      \n",
      " |      >>> import numpy as np\n",
      " |      >>> image_array = np.random.random((5, 5, 5))\n",
      " |      >>> plugin = determine_plugin(image_array)\n",
      " |      >>> print(plugin)\n",
      " |      \n",
      " |      Implementation Details\n",
      " |      ----------------------\n",
      " |      - The function first converts the image to a string representation.\n",
      " |      - If the image is a file path, it verifies the path and checks the file\n",
      " |        extension against the known plugins.\n",
      " |      - For each matching plugin, it tries to instantiate a reader and checks\n",
      " |        if it supports the image.\n",
      " |      - If the image is array-like, it uses a built-in reader designed for\n",
      " |        such objects.\n",
      " |      - Detailed logging is provided for troubleshooting purposes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  channel_names\n",
      " |      Returns\n",
      " |      -------\n",
      " |      channel_names: List[str]\n",
      " |          Using available metadata, the list of strings representing channel names.\n",
      " |  \n",
      " |  current_resolution_level\n",
      " |      Returns\n",
      " |      -------\n",
      " |      current_resolution_level: int\n",
      " |          The currently selected resolution level.\n",
      " |  \n",
      " |  current_scene\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scene: str\n",
      " |          The current operating scene.\n",
      " |  \n",
      " |  current_scene_index\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scene_index: int\n",
      " |          The current operating scene index in the file.\n",
      " |  \n",
      " |  dask_data\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dask_data: da.Array\n",
      " |          The image as a dask array with standard dimension ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the image contains mosaic tiles, data is returned already stitched together.\n",
      " |  \n",
      " |  data\n",
      " |      Returns\n",
      " |      -------\n",
      " |      data: np.ndarray\n",
      " |          The image as a numpy array with standard dimension ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the image contains mosaic tiles, data is returned already stitched together.\n",
      " |      Recommended to use `dask_data` for large mosaic images.\n",
      " |  \n",
      " |  dims\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dims: dimensions.Dimensions\n",
      " |          Object with the paired dimension names and their sizes.\n",
      " |  \n",
      " |  dtype\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype: np.dtype\n",
      " |          Data-type of the image array's elements.\n",
      " |  \n",
      " |  metadata\n",
      " |      Returns\n",
      " |      -------\n",
      " |      metadata: Any\n",
      " |          Passthrough to the base image reader metadata property.\n",
      " |          For more information, see the specific image format reader you are using\n",
      " |          for details on its metadata property.\n",
      " |  \n",
      " |  mosaic_tile_dims\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tile_dims: Optional[Dimensions]\n",
      " |          The dimensions for each tile in the mosaic image.\n",
      " |          If the image is not a mosaic image, returns None.\n",
      " |  \n",
      " |  ome_metadata\n",
      " |      Returns\n",
      " |      -------\n",
      " |      metadata: OME\n",
      " |          The original metadata transformed into the OME specfication.\n",
      " |          This likely isn't a complete transformation but is guarenteed to\n",
      " |          be a valid transformation.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          No metadata transformer available.\n",
      " |  \n",
      " |  physical_pixel_sizes\n",
      " |      Returns\n",
      " |      -------\n",
      " |      sizes: PhysicalPixelSizes\n",
      " |          Using available metadata, the floats representing physical pixel sizes for\n",
      " |          dimensions Z, Y, and X.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      We currently do not handle unit attachment to these values. Please see the file\n",
      " |      metadata for unit information.\n",
      " |  \n",
      " |  reader\n",
      " |      Returns\n",
      " |      -------\n",
      " |      reader: Reader\n",
      " |          The object created to read the image file type.\n",
      " |          The intent is that if the BioImage class doesn't provide a raw enough\n",
      " |          interface then the base class can be used directly.\n",
      " |  \n",
      " |  resolution_level_dims\n",
      " |      Returns\n",
      " |      -------\n",
      " |      resolution_level_dims: Dict[int, Tuple[int, ...]]\n",
      " |          resolution level dictionary of shapes.\n",
      " |  \n",
      " |  resolution_levels\n",
      " |      Returns\n",
      " |      -------\n",
      " |      resolution_levels: Tuple[int, ...]\n",
      " |          A tuple of valid resolution levels in the file.\n",
      " |  \n",
      " |  scenes\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scenes: Tuple[str, ...]\n",
      " |          A tuple of valid scene ids in the file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Scene IDs are strings - not a range of integers.\n",
      " |      \n",
      " |      When iterating over scenes please use:\n",
      " |      \n",
      " |      >>> for id in image.scenes\n",
      " |      \n",
      " |      and not:\n",
      " |      \n",
      " |      >>> for i in range(len(image.scenes))\n",
      " |  \n",
      " |  shape\n",
      " |      Returns\n",
      " |      -------\n",
      " |      shape: Tuple[int, ...]\n",
      " |          Tuple of the image array's dimensions.\n",
      " |  \n",
      " |  xarray_dask_data\n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray_dask_data: xr.DataArray\n",
      " |          The delayed image and metadata as an annotated data array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the image contains mosaic tiles, data is returned already stitched together.\n",
      " |  \n",
      " |  xarray_data\n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray_data: xr.DataArray\n",
      " |          The fully read image and metadata as an annotated data array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the image contains mosaic tiles, data is returned already stitched together.\n",
      " |      Recommended to use `xarray_dask_data` for large mosaic images.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'scale', 'time_interval'})\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from bioio_base.image_container.ImageContainer:\n",
      " |  \n",
      " |  scale\n",
      " |  \n",
      " |  time_interval\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from bioio_base.image_container.ImageContainer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bioio import BioImage\n",
    "\n",
    "help(BioImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioio_base as biob\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from bioio_base.types import MetaArrayLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BioImage' from 'bioio_base.image_container' (c:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\bioio_base\\image_container.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbioio_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_container\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BioImage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(BioImage\u001b[38;5;241m.\u001b[39m__abstractmethods__)  \u001b[38;5;66;03m# Check which abstract methods are missing\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BioImage' from 'bioio_base.image_container' (c:\\Users\\siege\\anaconda3\\envs\\preprocess-img\\lib\\site-packages\\bioio_base\\image_container.py)"
     ]
    }
   ],
   "source": [
    "from bioio_base.image_container import BioImage\n",
    "\n",
    "print(BioImage.__abstractmethods__)  # Check which abstract methods are missing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
