{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory above the current notebook to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_images import get_images_infoframe\n",
    "import paramiko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get chunk images .tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = False\n",
    "folder_path = '/run/user/1001/gvfs/smb-share:server=fs.ista.ac.at,share=drives/tnegrell/archive/siegegrp/AlVe/MORPHOMICS2.0_MICROGLIA_BRAIN_ATLAS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows = True\n",
    "# folder_path = r\"\\\\fs.ista.ac.at\\drives\\aventuri\\archive\\siegegrp\\AlVe\\MORPHOMICS2.0_MICROGLIA_BRAIN_ATLAS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 631 files...\n",
      "There are 631 files in folder_location\n"
     ]
    }
   ],
   "source": [
    "project_path = os.path.join(folder_path, \"chunk_images\")\n",
    "\n",
    "infoframe = get_images_infoframe(project_path, \n",
    "                                 extension='.tif',\n",
    "                                 conditions = ['Age', 'Sex', 'Animal', 'Slide'],\n",
    "                                 windows=windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Slide</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_1</td>\n",
       "      <td>Slide_4</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_1</td>\n",
       "      <td>Slide_4</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_1</td>\n",
       "      <td>Slide_4</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_3...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_1</td>\n",
       "      <td>Slide_4</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_1</td>\n",
       "      <td>Slide_4</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_1...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_2</td>\n",
       "      <td>Slide_2</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_1...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_2</td>\n",
       "      <td>Slide_2</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_0...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_2</td>\n",
       "      <td>Slide_2</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_3...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_2</td>\n",
       "      <td>Slide_2</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_0...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>18m</td>\n",
       "      <td>F</td>\n",
       "      <td>Animal_2</td>\n",
       "      <td>Slide_2</td>\n",
       "      <td>microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_2...</td>\n",
       "      <td>/run/user/1001/gvfs/smb-share:server=fs.ista.a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex    Animal    Slide  \\\n",
       "0    18m   F  Animal_1  Slide_4   \n",
       "1    18m   F  Animal_1  Slide_4   \n",
       "2    18m   F  Animal_1  Slide_4   \n",
       "3    18m   F  Animal_1  Slide_4   \n",
       "4    18m   F  Animal_1  Slide_4   \n",
       "..   ...  ..       ...      ...   \n",
       "626  18m   F  Animal_2  Slide_2   \n",
       "627  18m   F  Animal_2  Slide_2   \n",
       "628  18m   F  Animal_2  Slide_2   \n",
       "629  18m   F  Animal_2  Slide_2   \n",
       "630  18m   F  Animal_2  Slide_2   \n",
       "\n",
       "                                             file_name  \\\n",
       "0    microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...   \n",
       "1    microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...   \n",
       "2    microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_3...   \n",
       "3    microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_4...   \n",
       "4    microglia_Age_18m_Sex_F_Animal_1_Slide_4_seq_1...   \n",
       "..                                                 ...   \n",
       "626  microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_1...   \n",
       "627  microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_0...   \n",
       "628  microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_3...   \n",
       "629  microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_0...   \n",
       "630  microglia_Age_18m_Sex_F_Animal_2_Slide_2_seq_2...   \n",
       "\n",
       "                                             file_path  \n",
       "0    /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "1    /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "2    /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "3    /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "4    /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "..                                                 ...  \n",
       "626  /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "627  /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "628  /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "629  /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "630  /run/user/1001/gvfs/smb-share:server=fs.ista.a...  \n",
       "\n",
       "[631 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get one chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the row: Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Define the file name you are searching for\n",
    "search_file = \"microglia_Age_18m_Sex_F_Animal_1_Slide_0_seq_0_chunk_4_over_5_x__-137695_-127435__y__46205_47957__.tiff\"\n",
    "\n",
    "# Get the index of the row containing the file name\n",
    "index = infoframe.loc[infoframe['file_name'] == search_file].index\n",
    "\n",
    "# If you want to print or use the index\n",
    "print(f\"Index of the row: {index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_example = infoframe.iloc[243]\n",
    "\n",
    "age = chunk_example['Age']\n",
    "sex = chunk_example['Sex']\n",
    "animal = chunk_example['Animal']\n",
    "slide = chunk_example['Slide']\n",
    "filename = chunk_example['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f'/mnt/archive/archive/siegegrp/AlVe/MORPHOMICS2.0_MICROGLIA_BRAIN_ATLAS'\n",
    "function = f'CUDA_VISIBLE_DEVICES=0 trAIce img2swc'\n",
    "linux_folderpath = f' -ip {base_path}/chunk_images/{age}/{sex}/{animal}/{slide}/{filename}' \n",
    "\n",
    "cube_params = f' -wss \"(128, 128, 16)\" -wsb \"(128, 128, 16)\" -tp \"(0.3, 0.3, 1.0)\"'\n",
    "save_folderpath = f' -spd {base_path}/traced_microglia/{age}/{sex}/{animal}/{slide}/{filename} -mp ./ -spsl ./ -nw 1 -bsp ./'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = function + linux_folderpath + cube_params + save_folderpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=0 trAIce img2swc -ip /mnt/archive/archive/siegegrp/AlVe/MORPHOMICS2.0_MICROGLIA_BRAIN_ATLAS/chunk_images/18m/F/Animal_1/Slide_0/microglia_Age_18m_Sex_F_Animal_1_Slide_0_seq_3_chunk_1_over_5_x__-37461_-27220__y__25669_35929__.tif -wss \"(128, 128, 16)\" -wsb \"(128, 128, 16)\" -tp \"(0.3, 0.3, 1.0)\" -spd /mnt/archive/archive/siegegrp/AlVe/MORPHOMICS2.0_MICROGLIA_BRAIN_ATLAS/traced_microglia/18m/F/Animal_1/Slide_0/microglia_Age_18m_Sex_F_Animal_1_Slide_0_seq_3_chunk_1_over_5_x__-37461_-27220__y__25669_35929__.tif -mp ./ -spsl ./ -nw 1 -bsp ./\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSH connection details\n",
    "ssh_user = \"tnegrell\"\n",
    "ssh_host = \"10.6.46.11\"\n",
    "remote_command = command\n",
    "password = \"123456\" \n",
    "\n",
    "# Create an SSH client\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "try:\n",
    "    # Connect to the remote machine with a password\n",
    "    ssh.connect(ssh_host, username=ssh_user, password=password)\n",
    "\n",
    "    # Execute the command\n",
    "    stdin, stdout, stderr = ssh.exec_command(remote_command)\n",
    "\n",
    "    # Read and print the command's output\n",
    "    print(\"Command Output:\\n\", stdout.read().decode())\n",
    "    print(\"Command Error:\\n\", stderr.read().decode())\n",
    "finally:\n",
    "    # Close the SSH connection\n",
    "    ssh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import click\n",
    "from . import preprocess as img_preprocess\n",
    "from . import model_io\n",
    "from . import postprocess\n",
    "import subprocess\n",
    "import ast\n",
    "from typing import Union\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@click.group(chain=True)\n",
    "def cli():\n",
    "    pass\n",
    "\n",
    "\n",
    "def img2soma_func(img_path, soma_model_save_path, soma_locs, window_size_soma,\n",
    "                  overlap, target_px2mu, save_path_dataset,\n",
    "                  mat_path, dataset_name, num_workers, ignore_flags) -> Union[bool, str]:\n",
    "    \"\"\" Detect soma from the image file and save the results to the save_path\n",
    "\n",
    "        Args:\n",
    "            img_path (str): The path to the image file\n",
    "            soma_model_save_path (str): The path to the soma model\n",
    "            soma_locs (str): The path to save the segmented somas of soma model\n",
    "            window_size_soma (tuple): The size of the window for soma detection cubes (soma model)\n",
    "            overlap (tuple): The overlap of the window for soma detection cubes (soma model)\n",
    "            target_px2mu (tuple): The target pixel to micron ratio used to scale the image\n",
    "            save_path_dataset (str): The path to save the cubes for soma detection\n",
    "            mat_path (str): The path to save the mat file\n",
    "            dataset_name (str): The name of the dataset\n",
    "            num_workers (int): The number of workers to use\n",
    "            soma_model_name (str): The name of the soma detection model in models class\n",
    "            ignore_flags (bool): Whether to ignore flags. If True, it will run the function regardless of previous computations\n",
    "        Returns:\n",
    "            str: The path to the saved soma locations\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert arguments str type to tuple\n",
    "    window_size_soma = str(window_size_soma)\n",
    "    overlap = str(overlap)\n",
    "    target_px2mu = str(target_px2mu)\n",
    "\n",
    "    window_size_soma = ast.literal_eval(window_size_soma)\n",
    "    overlap = ast.literal_eval(overlap)\n",
    "    target_px2mu = ast.literal_eval(target_px2mu)\n",
    "\n",
    "    # Set dataset name based on imaris file\n",
    "    if not dataset_name:\n",
    "        dataset_name = os.path.basename(img_path).split(\".\")[0]\n",
    "\n",
    "    # Set paths and flag paths\n",
    "    datasets_path = os.path.join(save_path_dataset, dataset_name)\n",
    "    if soma_locs is None:\n",
    "        soma_locs = os.path.join(datasets_path, 'soma')\n",
    "    else:\n",
    "        soma_locs = os.path.join(soma_locs, dataset_name)\n",
    "    flag_path_data = os.path.join(datasets_path, 'flag_data')\n",
    "    flag_path_cubes = os.path.join(datasets_path, 'flag_cubes')\n",
    "    flag_path_mat = os.path.join(mat_path, dataset_name, 'flag_mat')\n",
    "\n",
    "    # Check if flag is set. If so, terminate\n",
    "    if (not ignore_flags) and os.path.exists(flag_path_data):\n",
    "        print(\"IMG to Soma was done already.\")\n",
    "        return soma_locs\n",
    "\n",
    "    # Make mat file from img file\n",
    "    print(\"=======Make mat files out of img/nd2 file=======\")\n",
    "    print(f\"img_path: {img_path}\")\n",
    "    # Check mat flag\n",
    "    if ignore_flags or (not os.path.exists(flag_path_mat)):\n",
    "        # Run shell script to make mat file. main.sh handles file types: ims, nd2, tiff\n",
    "        # result = subprocess.run(\n",
    "        #     f\"./main.sh make_datasets_file \\\"{img_path}\\\" \\\"./ims_reader\\\" \\\"{mat_path}\\\"\", shell=True)\n",
    "            \n",
    "        # # Check if error in reading data\n",
    "        # if result.returncode != 0:\n",
    "        #     print(\"See error above. Error in reading data.\")\n",
    "        #     return False\n",
    "\n",
    "        # Check file type\n",
    "        if img_path.endswith('.ims'):\n",
    "            data = img_preprocess.make_dataset_ims(img_path, mat_path)\n",
    "        elif img_path.endswith('.nd2'):\n",
    "            data = img_preprocess.make_dataset_nd2(img_path, mat_path)\n",
    "        elif img_path.endswith('.tif'):\n",
    "            data = img_preprocess.make_dataset_tif(img_path, mat_path)\n",
    "\n",
    "        # Set flag for creating mat file\n",
    "        open(flag_path_mat, 'w').close()\n",
    "    else:\n",
    "        data = None\n",
    "        print(\"Mat file already exists.\")\n",
    "\n",
    "    print(f\"=======Make Masks Soma=======\")\n",
    "    # Extract window size, overlap, and target pixel to micrometer out of input arguments\n",
    "    window_size_x = window_size_soma[0]\n",
    "    window_size_y = window_size_soma[1]\n",
    "    window_size_z = window_size_soma[2]\n",
    "\n",
    "    overlap_x = overlap[0]\n",
    "    overlap_y = overlap[1]\n",
    "    overlap_z = overlap[2]\n",
    "\n",
    "    # target_px2mu is used to scale in a way to get this ratio\n",
    "    target_x_px2mu = target_px2mu[0]\n",
    "    target_y_px2mu = target_px2mu[1]\n",
    "    target_z_px2mu = target_px2mu[2]\n",
    "\n",
    "    print(\n",
    "        f\"Target pixel/micrometer: x={target_x_px2mu}, y={target_y_px2mu}, z={target_z_px2mu}\")\n",
    "\n",
    "    if not os.path.exists(save_path_dataset):\n",
    "        os.makedirs(save_path_dataset)\n",
    "\n",
    "    # Check cubes flag\n",
    "    if ignore_flags or (not os.path.exists(flag_path_cubes)):\n",
    "        img_preprocess.make_mask_soma(\n",
    "            data = data,\n",
    "            file_path=os.path.join(\n",
    "                mat_path,\n",
    "                dataset_name,\n",
    "                \"dataset.mat\"),\n",
    "            dataset_name=dataset_name,\n",
    "            save_path_dataset=save_path_dataset,\n",
    "            window_size_x=window_size_x,\n",
    "            window_size_y=window_size_y,\n",
    "            window_size_z=window_size_z,\n",
    "            overlap_x=overlap_x,\n",
    "            overlap_y=overlap_y,\n",
    "            overlap_z=overlap_z,\n",
    "            target_x_px2mu=target_x_px2mu,\n",
    "            target_y_px2mu=target_y_px2mu,\n",
    "            target_z_px2mu=target_z_px2mu,\n",
    "            num_workers=num_workers)\n",
    "        # Make file flag_path\n",
    "        open(flag_path_cubes, 'w').close()\n",
    "    else:\n",
    "        print(\"Cubes already exists.\")\n",
    "\n",
    "    print(f\"=======Soma Detection Stage=======\")\n",
    "    print(f\"Soma location: {os.path.join(soma_locs, dataset_name)}\")\n",
    "    model_io.soma_detection(\n",
    "        soma_model_save_path, datasets_path, num_workers, soma_locs)\n",
    "\n",
    "    # Make file flag_path\n",
    "    open(flag_path_data, 'w').close()\n",
    "\n",
    "    print(f\"Segmented soma saved in {soma_locs}\")\n",
    "\n",
    "    return soma_locs\n",
    "\n",
    "\n",
    "def soma2branch_func(branch_model_save_path, save_path, window_size_branch, save_path_soma_locs,\n",
    "                     kernel_size, branch_segmented_save_path, num_workers, postprocess_flag,\n",
    "                     ignore_flags, dataset_name) -> Union[bool, str]:\n",
    "    \"\"\" Detect branches after detecting somas\n",
    "\n",
    "        This function first extract soma locations from the output of soma detection stage,\n",
    "        and apply the branch detection model for each cell. So, it will produce segmented\n",
    "        branches for each cell in seperate folders and files.\n",
    "\n",
    "        Args:\n",
    "            branch_model_save_path (str): The path to the branch model\n",
    "            save_path (str): The path to the soma locations\n",
    "            window_size_branch (tuple): The size of the window for data of branch detection\n",
    "            save_path_soma_locs (str): The path to save the cubes for branch detection\n",
    "            kernel_size (int): The size of the kernel for adaptive histogram equalization\n",
    "            branch_segmented_save_path (str): The path to save the segmented branches\n",
    "            num_workers (int): The number of workers to use\n",
    "            postprocess_flag (bool): Whether to apply postprocessing. If True, it will apply dilation, select connected component of the detected soma, erosion, and the return the mask as branches of soma.\n",
    "            ignore_flags (bool): Whether to ignore flags. If True, it will run the function regardless of previous computations\n",
    "            dataset_name (str): The name of the dataset\n",
    "        Returns:\n",
    "            str: The path to the saved branch segmentation\n",
    "    \"\"\"\n",
    "    # Convert arguments str type to tuple\n",
    "    window_size_branch = str(window_size_branch)\n",
    "    window_size_branch = ast.literal_eval(window_size_branch)\n",
    "\n",
    "    # Set flag paths and save path\n",
    "    flag_path_branch = os.path.join(\n",
    "        branch_segmented_save_path, dataset_name, 'flag_branch')\n",
    "    flag_path_soma = os.path.join(\n",
    "        save_path_soma_locs, dataset_name, 'flag_soma')\n",
    "    save_path_soma_locs = os.path.join(\n",
    "        save_path_soma_locs, dataset_name, 'branches_data')\n",
    "    branch_segmented_save_path = os.path.join(\n",
    "        branch_segmented_save_path, dataset_name, 'branch')\n",
    "\n",
    "    # Check if the branch flag is set. If so, terminate\n",
    "    if (not ignore_flags) and os.path.exists(flag_path_branch):\n",
    "        print(\"IMG to Branch was done already.\")\n",
    "        return True\n",
    "\n",
    "    if not os.path.exists(save_path_soma_locs):\n",
    "        os.makedirs(save_path_soma_locs)\n",
    "\n",
    "    print(f\"=======Extract Soma Location=======\")\n",
    "    print(f\"------------loading data from: {save_path}\")\n",
    "    print(f\"------------saveing data to: {save_path_soma_locs}\")\n",
    "\n",
    "    # Extract window size for branch detection\n",
    "    window_size_x = window_size_branch[0]\n",
    "    window_size_y = window_size_branch[1]\n",
    "    window_size_z = window_size_branch[2]\n",
    "    print(\n",
    "        f\"window_size_x_branch: {window_size_x} window_size_y_branch: {window_size_y} window_size_z_branch: {window_size_z}\")\n",
    "    \n",
    "    # Check soma flag for creating cubes for branch detection\n",
    "    if ignore_flags or (not os.path.exists(flag_path_soma)):\n",
    "        postprocess.soma_loc_detection(save_path, save_path_soma_locs,\n",
    "                                       window_size_x, window_size_y, window_size_z,\n",
    "                                       kernel_size, num_workers)\n",
    "\n",
    "        # Make the flag for data of branch detection\n",
    "        open(flag_path_soma, 'w').close()\n",
    "    else:\n",
    "        print(\"Soma location was done already.\")\n",
    "\n",
    "    if not os.path.exists(branch_segmented_save_path):\n",
    "        os.makedirs(branch_segmented_save_path)\n",
    "\n",
    "    print(f\"======= Branch Segmentation =======\")\n",
    "    print(f\"Loading model from {branch_model_save_path}\")\n",
    "    model_io.branch_detection(branch_model_save_path, save_path_soma_locs,\n",
    "                              branch_segmented_save_path, postprocess_flag)\n",
    "\n",
    "    # Make the flag for branch detection\n",
    "    open(flag_path_branch, 'w').close()\n",
    "\n",
    "    postprocess.reconstruct_img_with_segmented_mask(dataset_name)\n",
    "\n",
    "    print(f\"Branch segmented saved in {branch_segmented_save_path}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def branch2swc_func(branch_segmented_save_path) -> Union[bool, str]:\n",
    "    \"\"\" Extract SWC from the segmented branches\n",
    "\n",
    "        This function converts detected branches to SWC file from the output of soma2branch\n",
    "        stage. So, it will produce SWC files for each cell separately.\n",
    "\n",
    "        Args:\n",
    "            branch_segmented_save_path (str): The path to the segmented branches\n",
    "        Returns:\n",
    "            str: The path to save the SWC files\n",
    "    \"\"\"\n",
    "    # Extract SWC\n",
    "    postprocess.skeleton_extraction(branch_segmented_save_path)\n",
    "\n",
    "    print(f\"SWC saved in {branch_segmented_save_path}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def cube2branch_func(cube, point, branch_model_save_path, posprocess_flag) -> Union[bool, str]:\n",
    "    \"\"\" Detect branches for one cube for GUI purpose\n",
    "\n",
    "        This function is used for GUI purpose to detect branches for one cube. It will\n",
    "        produce segmented branches for the cube.\n",
    "\n",
    "        Args:\n",
    "            cube (np.array): The cube for branch detection\n",
    "            point (tuple): The point for the cube\n",
    "            branch_model_save_path (str): The path to the branch model\n",
    "            posprocess_flag (bool): Whether to apply postprocessing. If True, it will apply dilation, select connected component of the detected soma, erosion, and the return the mask as branches of soma.\n",
    "        Returns:\n",
    "            str: The path to the saved branch segmentation\n",
    "    \"\"\"\n",
    "    cube = np.array(cube['arr_0'])\n",
    "    # remove char in point string\n",
    "    point = point.replace(\"'\", \"\")\n",
    "    point = ast.literal_eval(point)\n",
    "    print(type(point))\n",
    "    segmented = model_io.branch_detection_cube(cube, point, branch_model_save_path, posprocess_flag)\n",
    "    return segmented\n",
    "\n",
    "\n",
    "@cli.command('img2soma')\n",
    "@click.option('--img_path', '-ip', type=str, required=True)\n",
    "@click.option('--soma_model_save_path', '-smsp', type=str, default='/opt/trAIce/trAIce/models/models_best_\\soma_2024may07.pth')\n",
    "@click.option('--soma_locs', '-sl', type=str, required=False, default=None)\n",
    "@click.option('--window_size_soma', '-wss', type=str, required=True, default=\"(128,128,16)\")\n",
    "@click.option('--overlap', '-o', type=str, required=True, default=\"(0,0,0)\")\n",
    "@click.option('--target_px2mu', '-tp', type=str, required=True, default=\"(2.5,2.5,0.8)\")\n",
    "@click.option('--save_path_dataset', '-spd', type=str, required=True)\n",
    "@click.option('--mat_path', '-mp', type=str, required=True)\n",
    "@click.option('--dataset_name', '-dn', type=str, required=False, default=None)\n",
    "@click.option('--num_workers', '-nw', type=int, required=True, default=1)\n",
    "@click.option('--soma_model_name', '-smn', type=str, required=True, default=\"CellSomaSegmentationModel\")\n",
    "@click.option('--ignore_flags', '-if', type=bool, required=True, default=False)\n",
    "def img2soma(img_path, soma_model_save_path, soma_locs, window_size_soma,\n",
    "             overlap, target_px2mu, save_path_dataset,\n",
    "             mat_path, dataset_name, num_workers, soma_model_name, ignore_flags) -> bool:\n",
    "    \"\"\" This function uses appropriate function calling for conversion of each image to detected\n",
    "        somas.\n",
    "        Intermediate steps are making cubes for soma detection, feed the model, and save the\n",
    "        results.\n",
    "\n",
    "        Args:\n",
    "            img_path (str): The path to the image file\n",
    "            soma_model_save_path (str): The path to the soma model\n",
    "            soma_locs (str): The path to save the segmented somas of soma model, as default save in the dataset folder\n",
    "            window_size_soma (tuple): The size of the window for soma detection cubes (soma model), default is (128, 128, 16)\n",
    "            overlap (tuple): The overlap of the window for soma detection cubes (soma model), default is (0, 0, 0)\n",
    "            target_px2mu (tuple): The target pixel to micron ratio used to scale the image, default is (2.5, 2.5, 0.8)\n",
    "            save_path_dataset (str): The path to save the cubes for soma detection\n",
    "            mat_path (str): The path to save the mat file\n",
    "            dataset_name (str): The name of the dataset, as default is the name of the ims/nd2/tif image file\n",
    "            num_workers (int): The number of workers to use, default is 1\n",
    "            soma_model_name (str): The name of the soma detection model in models class\n",
    "            ignore_flags (bool): Whether to ignore flags. If True, it will run the function regardless of previous computations. default is False\n",
    "        Returns:\n",
    "            str: The path to the saved soma locations\n",
    "\n",
    "        Sample command:\n",
    "            python main.py img2soma --img_path \"test/CX3CR1-EGFP_RETINA_20X.ims\" --target_px2mu \"(2.5, 2.5, 0.8)\" --save_path_dataset \"tmp\" --mat_path \"tmp\" --num_workers 4\n",
    "            -smsp \"models/models_best_soma_2024may07.pth\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep run time\n",
    "    start = time.time()\n",
    "\n",
    "    if not img2soma_func(img_path=img_path, soma_model_save_path=soma_model_save_path, soma_locs=soma_locs,\n",
    "                         window_size_soma=window_size_soma, overlap=overlap, target_px2mu=target_px2mu,\n",
    "                         save_path_dataset=save_path_dataset, mat_path=mat_path, dataset_name=dataset_name,\n",
    "                         num_workers=num_workers, ignore_flags=ignore_flags):\n",
    "        print(\"Error\")\n",
    "\n",
    "        return False\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"====> Total Run Time: {int((end - start) / 3600)}h {int((end - start) % 3600 / 60)}m {int((end - start) % 3600 % 60)}s\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "@cli.command('img2branch')\n",
    "@click.option('--img_path', '-ip', type=str, required=True)\n",
    "@click.option('--soma_locs', '-sl', type=str, required=False, default=None)\n",
    "@click.option('--soma_model_save_path', '-smsp', type=str, default='/opt/trAIce/trAIce/models/models_best_\\soma_2024may07.pth')\n",
    "@click.option('--branch_model_save_path', '-bms', type=str, default='/opt/trAIce/trAIce/models/36_UNETPromptGiven_128_128_16/')\n",
    "@click.option('--window_size_soma', '-wss', type=str, required=True, default=\"(128, 128, 16)\")\n",
    "@click.option('--window_size_branch', '-wsb', type=str, required=True, default=\"(512, 512, 32)\")\n",
    "@click.option('--overlap', '-o', type=str, required=True, default=\"(0, 0, 0)\")\n",
    "@click.option('--target_px2mu', '-tp', type=str, required=True, default=(2.5, 2.5, 0.8))\n",
    "@click.option('--save_path_dataset', '-spd', type=str, required=True)\n",
    "@click.option('--mat_path', '-mp', type=str, required=True)\n",
    "@click.option('--save_path_soma_locs', '-spsl', type=str, required=True)\n",
    "@click.option('--dataset_name', '-dn', type=str, required=False, default=None)\n",
    "@click.option('--kernel_size', '-ks', type=int, required=True, default=3)\n",
    "@click.option('--branch_segmented_save_path', '-bsp', type=str, required=True)\n",
    "@click.option('--num_workers', '-nw', type=int, required=True)\n",
    "@click.option('--soma_model_name', '-smn', type=str, required=True, default=\"CellSomaSegmentationModel\")\n",
    "@click.option('--postprocess_flag', '-ppf', type=bool, required=True, default=False)\n",
    "@click.option('--ignore_flags', '-if', type=bool, required=True, default=False)\n",
    "def img2branch(img_path, soma_model_save_path, soma_locs, branch_model_save_path,\n",
    "               window_size_soma, window_size_branch, overlap, target_px2mu,\n",
    "               save_path_dataset, mat_path, dataset_name, save_path_soma_locs,\n",
    "               kernel_size, branch_segmented_save_path, num_workers, soma_model_name,\n",
    "               postprocess_flag, ignore_flags) -> bool:\n",
    "    \"\"\" This function uses appropriate function calling for conversion of each image to branches.\n",
    "        Intermediate steps are making cubes for soma detection, feed the model, and save the\n",
    "        results for soma detection, extract soma locations, feed the branch detection model,\n",
    "        save the results for branch detection.\n",
    "\n",
    "        Args:\n",
    "            img_path (str): The path to the image file\n",
    "            soma_model_save_path (str): The path to the soma model\n",
    "            soma_locs (str): The path to save the segmented somas of soma model, as default save in the dataset folder\n",
    "            window_size_soma (tuple): The size of the window for soma detection cubes (soma model), default is (128, 128, 16)\n",
    "            overlap (tuple): The overlap of the window for soma detection cubes (soma model), default is (0, 0, 0)\n",
    "            target_px2mu (tuple): The target pixel to micron ratio used to scale the image, default is (2.5, 2.5, 0.8)\n",
    "            save_path_dataset (str): The path to save the cubes for soma detection\n",
    "            mat_path (str): The path to save the mat file\n",
    "            dataset_name (str): The name of the dataset, as default is the name of the ims/nd2/tif image file\n",
    "            num_workers (int): The number of workers to use, default is 1\n",
    "            soma_model_name (str): The name of the soma detection model in models class\n",
    "            ignore_flags (bool): Whether to ignore flags. If True, it will run the function regardless of previous computations. default is False\n",
    "            branch_model_save_path (str): The path to the branch model\n",
    "            window_size_branch (tuple): The size of the cubes for data of branch detection, default is (512, 512, 32)\n",
    "            save_path_soma_locs (str): The path to save the cubes for branch detection\n",
    "            kernel_size (int): The size of the kernel for adaptive histogram equalization, default is 3\n",
    "        Returns:\n",
    "            str: The path to the saved branch segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep run time\n",
    "    start = time.time()\n",
    "\n",
    "    if not img2soma_func(img_path=img_path, soma_model_save_path=soma_model_save_path, soma_locs=soma_locs,\n",
    "                         window_size_soma=window_size_soma, overlap=overlap, target_px2mu=target_px2mu,\n",
    "                         save_path_dataset=save_path_dataset, mat_path=mat_path, dataset_name=dataset_name,\n",
    "                         num_workers=num_workers, ignore_flags=ignore_flags):\n",
    "        print(\"Error\")\n",
    "        return False\n",
    "\n",
    "    if not soma2branch_func(branch_model_save_path=branch_model_save_path,\n",
    "                            save_path=[os.path.join(save_path_dataset,\n",
    "                                                    [os.path.basename(img_path).split(\".\")[0] if dataset_name is None else dataset_name][0],\n",
    "                                                    'soma') if soma_locs is None else soma_locs][0],\n",
    "                            window_size_branch=window_size_branch,\n",
    "                            save_path_soma_locs=save_path_soma_locs,\n",
    "                            dataset_name=os.path.basename(img_path).split(\".\")[0],\n",
    "                            kernel_size=kernel_size,\n",
    "                            branch_segmented_save_path=branch_segmented_save_path,\n",
    "                            num_workers=num_workers,\n",
    "                            postprocess_flag=postprocess_flag,\n",
    "                            ignore_flags=ignore_flags):\n",
    "        print(\"Error\")\n",
    "        return False\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"====> Total Run Time: {int((end - start) / 3600)}h {int((end - start) % 3600 / 60)}m {int((end - start) % 3600 % 60)}s\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "@cli.command('img2swc')\n",
    "@click.option('--img_path', '-ip', type=str, required=True)\n",
    "@click.option('--soma_model_save_path', '-smsp', type=str, default='/opt/trAIce/trAIce/models/models_best_\\soma_2024may07.pth')\n",
    "@click.option('--branch_model_save_path', '-bms', type=str, default='/opt/trAIce/trAIce/models/36_UNETPromptGiven_128_128_16/')\n",
    "@click.option('--window_size_soma', '-wss', type=str, required=True, default=\"(128, 128, 16)\")\n",
    "@click.option('--window_size_branch', '-wsb', type=str, required=True, default=\"(128, 128, 16)\")\n",
    "@click.option('--overlap', '-o', type=str, required=True, default=\"(0, 0, 0)\")\n",
    "@click.option('--target_px2mu', '-tp', type=str, required=True, default=\"(2.5, 2.5, 0.8)\")\n",
    "@click.option('--save_path_dataset', '-spd', type=str, required=True)\n",
    "@click.option('--mat_path', '-mp', type=str, required=True)\n",
    "@click.option('--save_path_soma_locs', '-spsl', type=str, required=True)\n",
    "@click.option('--dataset_name', '-dn', type=str, required=False, default=None)\n",
    "@click.option('--soma_locs', '-sl', type=str, required=False, default=None)\n",
    "@click.option('--kernel_size', '-ks', type=int, required=True, default=3)\n",
    "@click.option('--branch_segmented_save_path', '-bsp', type=str, required=True)\n",
    "@click.option('--num_workers', '-nw', type=int, required=True)\n",
    "@click.option('--ignore_flags', '-if', type=bool, required=True, default=False)\n",
    "@click.option('--soma_model_name', '-smn', type=str, required=True, default=\"CellSomaSegmentationModel\")\n",
    "@click.option('--postprocess_flag', '-ppf', type=bool, required=True, default=False)\n",
    "@click.option('--ignore_flags', '-if', type=bool, required=True, default=False)\n",
    "def img2swc(img_path, soma_model_save_path, branch_model_save_path,\n",
    "            window_size_soma, window_size_branch, soma_locs,\n",
    "            overlap, target_px2mu, save_path_dataset,\n",
    "            mat_path, dataset_name, soma_model_name,\n",
    "            save_path_soma_locs, kernel_size, postprocess_flag,\n",
    "            branch_segmented_save_path, num_workers, ignore_flags) -> bool:\n",
    "    \"\"\" This function uses appropriate function calling for conversion of each image to SWC files.\n",
    "        Intermediate steps are making cubes for soma detection, feed the model, and save the\n",
    "        results for soma detection, extract soma locations, feed the branch detection model,\n",
    "        save the results for branch detection, and extract SWC files.\n",
    "\n",
    "        Args:\n",
    "            img_path (str): The path to the image file\n",
    "            soma_model_save_path (str): The path to the soma model\n",
    "            soma_locs (str): The path to save the segmented somas of soma model, as default save in the dataset folder\n",
    "            window_size_soma (tuple): The size of the window for soma detection cubes (soma model), default is (128, 128, 16)\n",
    "            overlap (tuple): The overlap of the window for soma detection cubes (soma model), default is (0, 0, 0)\n",
    "            target_px2mu (tuple): The target pixel to micron ratio used to scale the image, default is (2.5, 2.5, 0.8)\n",
    "            save_path_dataset (str): The path to save the cubes for soma detection\n",
    "            mat_path (str): The path to save the mat file\n",
    "            dataset_name (str): The name of the dataset, as default is the name of the ims/nd2/tif image file\n",
    "            num_workers (int): The number of workers to use, default is 1\n",
    "            soma_model_name (str): The name of the soma detection model in models class\n",
    "            ignore_flags (bool): Whether to ignore flags. If True, it will run the function regardless of previous computations. default is False\n",
    "            branch_model_save_path (str): The path to the branch model\n",
    "            window_size_branch (tuple): The size of the cubes for data of branch detection, default is (512, 512, 32)\n",
    "            save_path_soma_locs (str): The path to save the cubes for branch detection\n",
    "            kernel_size (int): The size of the kernel for adaptive histogram equalization, default is 3\n",
    "            postprocess_flag (bool): Whether to apply postprocessing. If True, it will apply dilation, select connected component of the detected soma, erosion, and the return the mask as branches of soma. default is False\n",
    "            branch_segmented_save_path (str): The path to save SWC files\n",
    "        Returns:\n",
    "            str: The path to the saved SWC files\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep run time\n",
    "    start = time.time()\n",
    "\n",
    "    if not img2soma_func(img_path=img_path, soma_model_save_path=soma_model_save_path, soma_locs=soma_locs,\n",
    "                         window_size_soma=window_size_soma, overlap=overlap, target_px2mu=target_px2mu,\n",
    "                         save_path_dataset=save_path_dataset, mat_path=mat_path, dataset_name=dataset_name,\n",
    "                         num_workers=num_workers, ignore_flags=ignore_flags):\n",
    "        print(\"Error\")\n",
    "        return False\n",
    "\n",
    "    if not soma2branch_func(branch_model_save_path=branch_model_save_path,\n",
    "                            save_path=[os.path.join(save_path_dataset,\n",
    "                                                    [os.path.basename(img_path).split(\".\")[0] if dataset_name is None else dataset_name][0],\n",
    "                                                    'soma') if soma_locs is None else soma_locs][0],\n",
    "                            window_size_branch=window_size_branch,\n",
    "                            save_path_soma_locs=save_path_soma_locs,\n",
    "                            dataset_name=os.path.basename(img_path).split(\".\")[0],\n",
    "                            kernel_size=kernel_size,\n",
    "                            branch_segmented_save_path=branch_segmented_save_path,\n",
    "                            num_workers=num_workers,\n",
    "                            postprocess_flag=postprocess_flag,\n",
    "                            ignore_flags=ignore_flags):\n",
    "        print(\"Error\")\n",
    "        return False\n",
    "\n",
    "    # print(f\"branch_segmented_save_path {branch_segmented_save_path}\")\n",
    "    if not branch2swc_func(\n",
    "        branch_segmented_save_path=os.path.join(\n",
    "            branch_segmented_save_path, [\n",
    "            os.path.basename(img_path).split(\".\")[0] if dataset_name is None else dataset_name][0], 'branch')):\n",
    "        print(\"Error\")\n",
    "        return False\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"====> Total Run Time: {int((end - start) / 3600)}h {int((end - start) % 3600 / 60)}m {int((end - start) % 3600 % 60)}s\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cli()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioimag",
   "language": "python",
   "name": "bioimag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
